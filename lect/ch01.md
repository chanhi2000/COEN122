# Chapter 1

## The Computer Revolution
- Progress in computer technology
	- Underpinned by Moore’s Law
- Makes novel applications feasible
	- Computers in automobiles
	- Cell phones
	- Human genome project
	- World Wide Web
	- Search Engines


## CLASSES OF COMPUTERS
### Personal computers
- General purpose, variety of software
- Subject to cost/performance tradeoff

### Server computers
- Network based
- High capacity, performance, reliability
- Range from small servers to building sized

### Supercomputers
- High-end scientific and engineering calculations
- Highest capability but represent a small fraction of the overall computer market

### Embedded computers
- Hidden as components of systems
- Stringent power/performance/cost constraints


## THE POST-PC ERA
![fig1-01]()

### Personal Mobile Device (PMD)
- Battery operated
- Connects to the Internet
- Hundreds of dollars
- Smart phones, tablets, electronic glasses

### Cloud computing
- Warehouse Scale Computers (WSC)
- Software as a Service (SaaS)
- Portion of software run on a PMD and a portion run in the Cloud
- Amazon and Google


## WHAT YOU WILL LEARN
- How the hardware executes machine code
- The hardware/software interface
- What determines program performance
	- And how it can be improved
- How hardware designers improve performance
- What is parallel processing


## Understanding Performance
### Algorithm
- Determines number of operations executed

### Programming language, compiler, architecture
- Determine number of machine instructions executed per operation

### Processor and memory system
- Determine how fast instructions are executed

### I/O system (including OS)
- Determines how fast I/O operations are executed


## EIGHT GREAT IDEAS
- Design for __Moore’s Law__
- Use __abstraction__ to simplify design
- Make the __common case fast__
- Performance via __parallelism__
- Performance via __pipelining__
- Performance via __prediction__
- __Hierarchy__ of memories
- __Dependability__ via redundancy


## BELOW YOUR PROGRAM
### Application software
- Written in high-level language

### System software
- Compiler: translates HLL code tomachine code
- Operating System: service code
	- Handling input/output
	- Managing memory and storage
	- Scheduling tasks & sharing resources

### Hardware
- Processor, memory, I/O controllers


## LEVELS OF PROGRAM CODE
### High-level language
- Level of abstraction closer to problem domain
- Provides for productivity and portability

### Assembly language
- Textual representation of instructions

### Hardware representation
- Binary digits (bits)
- Encoded instructions and data


## COMPONENTS OF A COMPUTER
### Same components for all kinds of computer
- Desktop, server, embedded

### Input/output includes
- User-interface devices
	- Display, keyboard, mouse
- Storage devices
	- Hard disk, CD/DVD, flash
- Network adapters
	- For communicating with other computers


## INSIDE THE PROCESSOR (CPU)
### Datapath:
- performs operations on data

### Control:
- sequences datapath, memory, ...

### Cache memory
- Small fast SRAM memory for immediate access to data


## ABSTRACTIONS
- Abstraction helps us deal with complexity
	- Hide lower-level detail
- One important abstraction: __Instruction set architecture__ (ISA)
	- hardware/software interface
	- includes anything a programmer needs to know to make a binary machine language work
		- \# instructions,
		- formats,
		- addressing modes,
		- …
	- decides workload b/w software & hardware
- __An implementation__: hardware that obeys the architecture abstract
	- An architecture can have several different implementations
- Examples of instruction set architectures:
	- MIPS, SPARC, ARM, and others


## POWER VS. PERFORMANCE
$$
\text{POWER}=
\left(\begin{matrix}
\text{capacitive}\\\text{load}
\end{matrix}\right)
\left(\begin{matrix}
\text{voltage}
\end{matrix}\right)^2
\left(\begin{matrix}
\text{frequency}\\text{switched}
\end{matrix}\right)
$$
- __Power__ is a linear function of clock rate
- __Performance__ is a linear function of clock rate
- Power issues: overheating and PMD
- Resolving power issues in past:
	- Decrease voltage $$\to\:5\:\text{V}\to1\:\text{V}$$ in 20 years
	- Cooling – remove heat
- The power wall
	- We can’t reduce voltage further
	- We can’t remove more heat
- How else can we improve performance?
- __One possible solution__: multi cores
	- Power is a function of $$\sqrt{\text{area}}=\sqrt{\#\text{cores}}$$
	- After 2006, desktops and severs are with multi core


## MICROPROCESSORS
- multicore-microprocessor
	- More than one processor per chip
- Requires explicitly parallel programming
	- Compare with instruction level parallelism
		- Hardware executes multiple instructions at once
		- Hidden from the programmer
	- Hard to do
		- Programming for performance
		- Load balancing
		- Optimizing communication and synchronization


## RESPONSE TIME & THROUGHPUT
#### Response time
- How long it takes to do a task

#### Throughput
- Total work done per unit time
	- *e.g.*, tasks/transactions/… per hour
- How are response time and throughput affected by
	- Replacing the processor with a faster version?
	- Adding more processors?
- We’ll focus on response time for now…


## RELATIVE PERFORMANCE
$$\text{performance}=\frac{1}{\text{exec. time}}$$
- “$$x$$ is $$n$$ time faster than $$y$$”
	$$
	\frac{\text{perf}(x)}{\text{perf}(y)}
	=\frac{t_{\text{exec}}(y)}{t_{\text{exec}}(x)}
	=n
	$$
- __Example__: time taken to run a program:
	- $$10\:\text{s}$$ on A,
    - $$15\:\text{s}$$ on B

$$
\begin{align*}
n&=\frac{\text{perf}(A)}{\text{perf}(B)}\\
&=\frac{\tfrac{1}{10}}{\tfrac{1}{15}}=1.5
\end{align*}
$$

$$
\therefore\:A\text{ is 1.5 times faster than }B
$$


## MEASURING EXECUTION TIME
### Elapsed time
- Total response time, including all aspects
	- Processing, I/O, OS overhead, idle time
- Determines system performance
### CPU time
- Time spent processing a given job
	- Discounts I/O time, other jobs’ shares


## CPU CLOCKING
- Operation of digital hardware governed by a constant-rate clock
![fig1-02]()
- __Clock period__: duration of a clock cycle $$l_\text{cycle}$$
- __Clock frequency__: cycles per second, $$r_\text{CLK}$$
 	- *e.g.*,
	$$
	\begin{align*}
	r_{\text{CLK}}&=4\:\text{GHz}=4\times10^{9}\:\frac{\text{cycles}}{\text{sec}}\\
	l_{\text{cycle}}&=\frac{1}{r_{\text{CLK}}}=\frac{1}{(4\times10^9)}=250\:\text{ps}
	\end{align*}
	$$


## CLOCK CYCLES vs. CLOCK RATE?
$$
\underset{\text{Clock rate}}{r_\text{CLK}}
\equiv\underset{\text{Clock frequency}}{f_\text{CLK}}
$$

$$
\underset{\text{Clock period}}{T_\text{CLK}}\equiv
\underset{\text{Cycle time}}{t_\text{cycle}}\equiv
\underset{\text{Cycle length}}{l_\text{cycle}}
$$
### How they are related?
$$
r_{\text{CLK}}=\frac{1}{l_{\text{cycle}}}
$$


## CPU TIME
$$
\begin{align*}
\text{CPU Time}&=\left(\#\:\text{cycles}\right)\left(t_{\text{cycle}}\right)\:\:\:\:\left<r_{\text{CLK}}=\frac{1}{l_{\text{cycle}}}\right>\\
&=\frac{\#\:\text{cycles}}{(r_{\text{CLK}})}
\end{align*}
$$
- Performance improved by
	- Reducing number of clock cycles
	- Increasing clock rate
	- Hardware designer must often trade off clock
	- rate against cycle count

### EXAMPLE: CPU TIME
- Computer A: $$2\:\text{GHz}$$ clock, $$10\:\text{s}$$ CPU time
- Designing Computer B
	- Aim for $$6\:\text{s}$$ CPU time
	- Can do faster clock, but causes $$1.2$$ times clock cycles
	- How fast must Computer B clock be?

Given
$$
\left\{
\begin{align*}
r_{\text{CLK}}(A)&=2\text{GHz}=2\times10^9\:\text{Hz}\\
\text{CPU time}(A)&=10\:\text{sec}\\
\text{CPU time}(B)&=6\:\text{sec}\\
\frac{\text{#CYCLE}(B)}{\text{#CYCLE}(A)}&=1.2
\end{align*}
\right\}
$$

$$
\begin{align*}
r_{\text{CLK}}(B)&=\frac{(\#\:\text{#CYCLES}(B))}{\text{CPU time(B)}}\\
&=\frac{\left(1.2\right)(\#\:\text{#CYCLES}(A))}{\text{CPU time(B)}}\:\:\:\:\left<\#\:\text{cycles}=(\text{CPU time})(r_{\text{CLK}})\right>\\
&=\frac{(1.2)(\text{CPU time}(A))(r_{\text{CLK}}(A))}{\text{CPU time(B)}}\\
&=\frac{(1.2)(10)(2\times10^9)}{(6)}\\
&=4\times10^9\:\text{Hz}\\
\end{align*}
$$

## INSTRUCTION COUNT AND CPI
$$
\begin{align*}
\begin{matrix}
\text{Clock}\\\text{cycles}
\end{matrix}&=\left(\begin{matrix}
\text{Instruction}\\\text{counts}
\end{matrix}\right)\times\left(\begin{matrix}
\text{Cycles}\\\text{per Instruction}
\end{matrix}\right)
\end{align*}
$$

$$
\begin{align*}
\begin{matrix}
\text{CPU}\\\text{Time}
\end{matrix}&=\left(\begin{matrix}
\text{Instruction}\\\text{counts}
\end{matrix}\right)\times\left(\text{CPI}\right)\times
\left(\begin{matrix}
\text{Clock Cycle}\\\text{Time}
\end{matrix}\right)\\
&=\frac{\left(\begin{matrix}
\text{Instruction}\\\text{counts}
\end{matrix}\right)\times\left(\text{CPI}\right)}{\left(\begin{matrix}
\text{Clock}\\\text{Rate}
\end{matrix}\right)}
\end{align*}
$$

### Instruction Count for a program
- Determined by __program__, __ISA__ and __compiler__
### Average cycles per instruction
- Determined by __CPU hardware__
- If different instructions have different CPI
	- Average CPI affected by instruction mix


### EXAMPLE:
Which is faster, and by how much?
$$
\begin{align*}
\text{COMPUTER A}:&
\begin{cases}
t_\text{cycle}=250\:\text{ps}\\
\text{CPI}=2.0
\end{cases}\\
\text{COMPUTER B}:&
\begin{cases}
t_\text{cycle}=500\:\text{ps}\\
\text{CPI}=1.2
\end{cases}
\end{align*}
$$

Given CPU Time(s):
$$
\left\{\begin{align*}
\text{CPU time}(A)&=\left[\text{IC}(A)\right]\left[\text{CPI}(A)\right]\left[t_\text{cycle}(A)\right]\\
\text{CPU time}(B)&=\left[\text{IC}(B)\right]\left[\text{CPI}(B)\right]\left[t_\text{cycle}(B)\right]\\
\end{align*}\right\}
$$

$$
\require{cancel}
\begin{align*}
\frac{\text{CPU time}(A)}{\text{CPU time}(B)}&=\frac{\cancel{\left[\text{IC}(A)\right]}\left[\text{CPI}(A)\right]\left[t_\text{cycle}(A)\right]}{\cancel{\left[\text{IC}(B)\right]}\left[\text{CPI}(B)\right]\left[t_\text{cycle}(B)\right]}\\
&\left\{\text{IC}(A)=\text{IC}(B)=\text{IC}\right\}\\
&=\frac{\left[\text{CPI}(A)\right]\left[t_\text{cycle}(A)\right]}{\left[\text{CPI}(B)\right]\left[t_\text{cycle}(B)\right]}\\
&=\frac{(2.0)\left(250\times10^{-12}\right)}{(1.2)\left(500\times10^{-12}\right)}=\frac{1}{1.2}
\end{align*}
$$

$$
\therefore\:1.2(\text{CPU time}(A))=\text{CPU time}(B)
$$


## CPI IN MORE DETAIL:
- If different instruction classes take different numbers of cycles
$$
\text{#CYCLES}=\sum_{i=1}^{n}{\left[\text{CPI}(i)\right]\left[\text{IC}(i)\right]}
$$
- weighted average CPI
$$
\begin{align*}
\text{CPI}&=\frac{\text{#CYCLES}}{\text{IC}}\\
&=\sum_{i=1}^{n}{\left[\frac{\left[\text{CPI}(i)\right]\left[\text{IC}(i)\right]}{\text{IC}}\right]}\\
&=\sum_{i=1}^{n}{\left[\text{CPI}(i)\right]\left[f_\text{rel}\right]}
\end{align*}
$$
where
$$
\begin{cases}
f_\text{rel}:&\text{relative frequency}=\frac{\text{IC}(i)}{\text{IC}}\\
\text{#CYCLES}:&\text{Clock cycles}\\
\text{IC}:&\text{Instruction count}\\
\text{CPI}:&\text{Cycles per instruction}\\
\end{cases}
$$

### EXAMPLE
What is $$\text{CPI}_\text{avg}$$?

| i | 1 | 2 | 3 | 4 |
| - | - | - | - | - |
| $$\text{instruction}$$ | A | B | C | D |
| $$\text{CPI}(i)$$ | 5 | 6 | 1 | 2 |
| $$f_\text{instr}(i)$$ | 15% | 10% | 20% | 55% |

$$
\left\{\begin{align*}
\text{#CYCLES(A)}&=\left(f_\text{instr}(A)\right)(n)(\text{CPI}(A))\\
\text{#CYCLES(B)}&=\left(f_\text{instr}(B)\right)(n)(\text{CPI}(B))\\
\text{#CYCLES(C)}&=\left(f_\text{instr}(C)\right)(n)(\text{CPI}(C))\\
\text{#CYCLES(D)}&=\left(f_\text{instr}(D)\right)(n)(\text{CPI}(D))\\
\end{align*}\right\}
$$

$$
\begin{align*}
\text{#CYCLES}&=\sum_{i=1}^{n}{\text{#CYCLES}(i)}\\
&=(n)\left[\left(f_\text{instr}(A)\right)\left(\text{CPI}(A)\right)+\left(f_\text{instr}(B)\right)\left(\text{CPI}(B)\right)+\left(f_\text{instr}(C)\right)\left(\text{CPI}(C)\right)+\left(f_\text{instr}(D)\right)\left(\text{CPI}(D)\right)\right]\\
&=(n)\left[(0.15)(5)+(0.10)(6)+(0.20)(1)+(0.55)(2)\right]\\
&=2.65n
\therefore\:\text{CPI}_\text{avg}&=\frac{1}{n}\text{#CYCLES}\\
&=2.65
\end{align*}
$$

## CPI EXAMPLE
Alternative compiled code sequences using instructions in classes A, B, C

| class | A | B | C |
| :---: | - | - | - |
| CPI for class | 1 | 2 | 3 |
| IC in sequence 1 | 2 | 1 | 2 |
| IC in sequence 2 | 4 | 1 | 1 |

$$
\begin{align*}
\text{IC}(1)&=2+1+2=5\\
\text{#CYCLES}(1)&=(\text{IC}(1))(\text{CPI}(1))\\
&=1(2)+2(1)+3(2)=10\\
\text{CPI}(1)&=\frac{\text{#CYCLES}(1)}{\text{IC}(1)}\\
&=\frac{1(2)+2(1)+3(2)}{2+1+2}=2\\\\
\text{IC}(2)&=4+1+1\\
\text{#CYCLES}(2)&=(\text{IC}(2))(\text{CPI}(2))\\
&=1(4)+2(1)+3(1)=9\\
\text{CPI}(2)&=\frac{\text{#CYCLES}(2)}{\text{IC}(2)}\\
&=\frac{1(4)+2(1)+3(1)}{4+1+1}=2
\end{align*}
$$


## PERFORMANCE SUMMARY
$$
\begin{align*}
\text{CPU Time}&=\left(\frac{\text{instruction}}{\text{program}}\right)\left(\frac{\text{clock cycles}}{\text{instruction}}\right)\left(\frac{\text{seconds}}{\text{clock cycles}}\right)
\end{align*}
$$
### Performance depends on
- __Algorithm__: affects $$\text{IC}$$, possibly $$\text{CPI}$$
- __Programming language__: affects $$\text{IC}$$, $$\text{CPI}$$
- __Compiler__: affects $$\text{IC}$$, $$\text{CPI}$$
- __Instruction__ set architecture: affects $$\text{IC}$$, $$\text{CPI}$$, $$T_c$$


## ONE MORE EXAMPLE
- Use following instruction mix, find
	- percentage of all memory accesses that are for data (vs inst.)
	- percentage of all memory accesses that are reads (vs. writes)

| arithmetic | load | store | branch |
| :--------: | :--: | :---: | :----: |
| 50% | 30% | 15% | 5% |

```
lw $1 300($2) 	;$1 <- mem[$2+300]
sw $1 300($2) 	;mem[$2+300] <- $1
```

$$
\require{cancel}
\begin{align*}
\frac{\text{data}}{\text{instruction}}&=\frac{\text{# mem access(data)}}{\text{# mem access total}}\\
&=\frac{(0.3)n+(0.15)n}{n+\underset{\text{lw}}{(0.3)n}+\underset{\text{sw}}{(0.15)n}}\\
&=\frac{0.45\cancel{n}}{1.45\cancel{n}}\\
\\
\frac{\text{read}}{\text{instruction}}&=\frac{\text{# mem access(read)}}{\text{# mem access total}}\\
&=\frac{(0.3)n}{n+\underset{\text{lw}}{(0.3)n}+\underset{\text{sw}}{(0.15)n}}\\
&=\frac{0.3\cancel{n}}{1.45\cancel{n}}
\end{align*}
$$


## SPEC CPU BENCHMARK
- Programs used to measure performance
	- Supposedly typical of actual workload
- Standard Performance Evaluation Corp (SPEC)
	- Develops benchmarks for CPU, I/O, Web, …
- SPEC CPU2006
	- Elapsed time to execute a selection of programs
		- Negligible I/O, so focuses on CPU performance
	- Normalize relative to reference machine
	- Summarize as geometric mean of performance ratios
		- CINT2006 (integer) and CFP2006 (floating-point)


## PITFALL: AMDAHL's LAW
- Improving an aspect of a computer and expecting a proportional improvement in overall performance
- Example: multiply accounts for 80s/100s
	- How much improvement in multiply performance to get 5x overall?
- Corollary: make the common case fast


## PITFALL: MIPS as a PERFORMANCE METRIC
__MIPS__: Millions of Instructions Per Second	
- Doesn’t account for
	- Differences in ISAs between computers
	- Differences in complexity between instructions
- CPI varies between programs on a given CPU


## EXAMPLE
- 2 machines
	 - __A__: floating-point (FP) hardware
	 - __B__: without FP, all integer instructions takes 2 cycles
- program P with instructions mix:

| instruction type | % | CPI on A | #integer instruction on B |
| :--------------- | - | :------: | :-----------------------: |
| FP multiplication | 10% | 6 |  30 |
| FP add | 15% | 4 | 20 |
| FP divide | 5% | 20 | 50 |
| integer instruction | 70% | 2 | 1 |

- Both machines have a clock rate of $$500\:\text{GHz}$$
- CPIs for both machines?
- MIPS rates of both machines? which one is the higher?
- If A needs $$n$$ instructions for program $$P$$, how many integer instructions does B require for the same program?
- CPU times of P on the A & B? Which one is faster?
- What conclusion can you get about the MIPS


## CONCLUSION
- Hierarchical layers of abstraction
	- In both hardware and software
- Instruction set architecture
	- The hardware/software interface
- Execution time: the best performance measure
- Power is a limiting factor	
	- Use parallelism to improve performance




